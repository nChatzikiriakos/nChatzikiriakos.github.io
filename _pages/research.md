---
layout: archive
title: "Research"
permalink: /research/
author_profile: true
header:
  og_image: "research/ecdf.png"
---

### Finite Sample Identification of Dynamical Systems 

### Active Learning of Dynamical Systems

### Uncertainty Quantification for data-driven control
A key challenge in providing data-driven control schemes with end-to-end guarantees lies in handling the uncertainty carried by the data. 
While there exist indirect data-driven control schemes for LTI systems that are equipped with end-to-end guarantees there is still an open gap, especially when it come to considering the interplay between finite sample identification error bounds and a controller that is robust with respect to this error. 
Further, indirect data-driven control for nonlienar systems 

<!-- One of the key goals is to explore a central challenge in data-driven control: handling the inherent uncertainty in data.
In this project we want to shed light on a central problem in data-based (control) methods, namely handling the uncertainty the data inherently carries.
In particular, we consider direct and indirect control methods and analyze to what extent the methods are robust to the uncertainty of the data, i.e., under which conditions on the uncertainty they still produce trustworthy results.

The overarching key queestion this project aims to consider is whether it is better to first map data to models and then apply model-based control design techniques (indirect method) or to map data to controllers (direct method). In particular, we want to take the uncertainty that is due to the used data into account. Robustness with reprect to this uncertainty should be carefully considered, which is why we are interested in the following fundamental questions:  (Q2) When robustness guarantees must be provided, is it less conservative to use an indirect or a direct method? (Q3) When does projecting the data onto a model class reduce the uncertainty compared to using uncompressed data?
To find answers to these questions it is necessary to quantify the uncertainty pertaining the two approaches.
For the indirect method, this comes down to characterizing the uncertainty around a model estimate which is obtained via system identification.
A particular goal is to reduce the conservatism typically associated with the provided uncertainty regions and relax restrictive assumptions which are often still present in literature.
For the direct method, quantifying uncertainty depends on the considered method. Thus, we will consider concrete examples, e.g. from model-free reinforcement learning.
The important observation that we want to use is that uncertainty can again be related to the outcome of an identification problem, this time not of the system's model but of other quantities (e.g. the controller itself).
One of the project's goals will then be to leverage this observation to propose an approach to uncertainty quantification in direct control. -->

This page is still under construction
